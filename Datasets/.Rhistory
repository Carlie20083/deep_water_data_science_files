tmp.sales2 <- tmp.sales2 * log(store.df$p1price) / log(store.df$p2price)
install.packages(c("cluster", "codetools", "colorspace", "DoE.base", "evaluate", "R6", "stringi"))
library(car)  # use the random some function
some(store.df, 10)
se <- function(x) { sd(x) / sqrt(length(x)) }
se(store.df$store.visits)
store.df <- data.frame(matrix(NA, ncol=10, nrow=k.stores*k.weeks))
names(store.df) <- c("storeNum", "Year", "Week", "p1sales", "p2sales",
"p1price", "p2price", "p1prom", "p2prom", "country")
head(store.df)
dim(store.df)  #check dimensions of the data frame
store.num <- 101:(100+k.stores)
(store.cty <- c(rep("US", 3), rep("DE", 5), rep("GB", 3), rep("BR", 2),
rep("JP", 4), rep("AU", 1), rep("CN", 2)))  #rep =repeats stats
se(store.df$store.visits)
se <- function(x) { sd(x) / sqrt(length(x)) }
store.df <- data.frame(matrix(NA, ncol=10, nrow=k.stores*k.weeks))
names(store.df) <- c("storeNum", "Year", "Week", "p1sales", "p2sales",
"p1price", "p2price", "p1prom", "p2prom", "country")
head(store.df)
dim(store.df)  #check dimensions of the data frame
store.num <- 101:(100+k.stores)
(store.cty <- c(rep("US", 3), rep("DE", 5), rep("GB", 3), rep("BR", 2),
rep("JP", 4), rep("AU", 1), rep("CN", 2)))  #rep =repeats stats
length(store.cty)    # make sure the country list is the right length
#replace the appropriate columns in the data frame with those values,
#using rep() to expand the vectors to match the number of stores and weeks
store.df$storeNum <- rep(store.num, each=k.weeks)
store.df$country  <- rep(store.cty, each=k.weeks)
rm(store.num, store.cty)    # clean up
(store.df$Week <- rep(1:52, times=k.stores*2))
(store.df$Year  <- rep(rep(1:2, each=k.weeks/2), times=k.stores))
#check the overall data structure with str()
str(store.df)
#Redefine store.df$storeNum and store.df$country
#as categorical using factor():
store.df$storeNum <- factor(store.df$storeNum)
store.df$country  <- factor(store.df$country)
str(store.df)
#Simulating Data Points
set.seed(98250)  # a favorite US postal code
#use the binomial distribution that counts the number of “heads”
#in a collection of coin tosses (where the coin can have any
#proportion of heads, not just 50 %).
#For every row of the store data, as noted by
#n=nrow(store.df), we draw from a distribution repre-
#senting the number of heads in a single coin toss (size=1)
#with a coin that has probability p=0.1 for product 1 and p=0.15
#for product 2. In other words, we arbitrarily assign a 10 % likelihood
#of promotion for product 1, and 15 % likelihood for product 2 and then
#randomly determine which weeks have promotions.
store.df$p1prom <- rbinom(n=nrow(store.df), size=1, p=0.1)  # 10% promoted
store.df$p2prom <- rbinom(n=nrow(store.df), size=1, p=0.15) # 15% promoted
head(store.df)  # check the data so far?
# sales data, using poisson (counts) distribution, rpois()
# first, the default sales in the absence of promotion
tmp.sales1 <- rpois(nrow(store.df), lambda=120)
tmp.sales2 <- rpois(nrow(store.df), lambda=100)
#scale sales according to the ratio of log(price)
tmp.sales1 <- tmp.sales1 * log(store.df$p2price) / log(store.df$p1price)
tmp.sales2 <- tmp.sales2 * log(store.df$p1price) / log(store.df$p2price)
head(store.df)
rm(list=ls())   #clears all object
store.num <- factor(c(3, 14, 21, 32, 54))  #store Id
store.rev <- c(543, 654, 345, 678, 234)  # # store revenue, $1000
store.visits  <-  c(45, 78, 32, 56, 34)  # visits, 1000s
store.manager <-c("Annie", "Bert", "Carla", "Dave", "Ella")
#putting parentheses around the whole expression, evaluate the
#resulting object (store.df). This has the same effect as assigning the object
#and then yping its name again to see its contents.
(store1.df <- data.frame(store.num, store.rev, store.visits,
store.manager, stringsAsFactors = FALSE))
se(store1.df$store.visits)
se <- function(x) { sd(x) / sqrt(length(x)) }
se(store1.df$store.visits)
mean(store.df$store.visits) + 1.96 * se(store.df$store.visits)
se(store1.df$store.visits)
mean(store.df$store.visits) + 1.96 * se(store.df$store.visits)
mean(store1.df$store.visits) + 1.96 * se(store1.df$store.visits)
x<- store1.df$store.visits
se <- function(x) {
# computes standard error of the mean
tmp.sd <- sd(x)      # standard deviation
tmp.N  <- length(x)  # sample size
tmp.se <- tmp.sd / sqrt(tmp.N)   # std error of the mean
return(tmp.se)
}
se
se1 <- function(x) {
# computes standard error of the mean
tmp.sd <- sd(x)      # standard deviation
tmp.N  <- length(x)  # sample size
tmp.se <- tmp.sd / sqrt(tmp.N)   # std error of the mean
return(tmp.se)
}
se1(store1.df$store.visits)
data <- read.table(header=TRUE, text='
id weight
1     20
2     27
3     24
')
data
ata$size      <- c("small", "large", "medium")
data$size      <- c("small", "large", "medium")
data[["Frame"]] <- c("Wide", "Narrow", "Flat")
data[,"price"]  <- c(100, 75, 234)
data$orders      <- 0   # Use the same value (0) for all rows
data
data
data[["orders"]] <- NULL
data
data
install.packages(c("forecast", "mnormt", "rmarkdown", "rsconnect"))
install.packages(c("forecast", "mnormt", "rmarkdown", "rsconnect"))
install.packages(c("forecast", "mnormt", "rmarkdown", "rsconnect"))
install.packages(c("forecast", "mnormt", "rmarkdown", "rsconnect"))
install.packages(c("forecast", "mnormt", "rmarkdown", "rsconnect"))
install.packages(c("forecast", "mnormt", "rmarkdown", "rsconnect"))
install.packages(c("forecast", "mnormt", "rmarkdown", "rsconnect"))
install.packages(c("forecast", "mnormt", "rmarkdown", "rsconnect"))
install.packages("readx1")
library("readx1")
library(ggplot2)
df
install.packages("readx1")
library("readx1")
install.packages('googleVis')
library("mlogit")
?mlogit.data
cbc1.df <- read.csv("https://raw.githubusercontent.com/josepcurto/Customer-Analytics/master/customer_data.csv", header = T))
cbc<- read.csv("https://raw.githubusercontent.com/josepcurto/Customer-Analytics/master/customer_data.csv", header = T)
View(cbc)
update.packages()
clogit <- read.csv("~/Desktop/everything R/R_Datasets/clogit.csv",
col.names=c("mode","ttme","invc","invt","gc","chair","hinc",
"psize","indj","indi","aasc","tasc","basc","casc",
"hinca","psizea","z","nij","ni"), na.strings="-999")
#checking the data
#Once the data has been add to R. it is a
#good idea to review it to see what values and data types you are working with
summary(clogit)
str(clogit)
install.packages("rmarkdown")
```
library("mosaic", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
favstats(~fastest, data=m111survey)
library("tigerstats", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
favstats(~fastest, data=m111survey)
xtab="fastest speed (mph)"
densityplot(~fastest, data=m111survey
xtab="fastest speed (mph)"
ytab- "fastest speed ever driven")
densityplot(~fastest, data=m111survey,
xtab="fastest speed (mph)",
ytab- "fastest speed ever driven")
densityplot(~fastest, data=m111survey,
xlab="Fastest speed (mph)",
main= "Fastest speed ever driven")
densityplot(~fastest, data=m111survey,
xlab="Fastest speed (mph)",
main= "Fastest speed ever driven")
library("pander", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
setwd("~/WorkingProjects")
Pandoc.convert(F=MD_Starterfile.mdm, format="pdf", options = "s")
Pandoc.convert(F="MD_Starterfile.md", format="pdf", options = "s")
Pandoc.convert(f="MD_Starterfile.md", format="pdf", options = "-s")
pandoc.convert(f="MD_Starterfile.md", format="pdf", options = "-s")
setwd("~/WorkingProjects")
setwd("~/")
output: word.doc
knitr::opts_chunk$set(echo = TRUE)
summary(clogit)  #summary function
clogit <- read.csv("~/Desktop/everything R/R_Datasets/clogit.csv",
col.names=c("mode","ttme","invc","invt","gc","chair","hinc",
"psize","indj","indi","aasc","tasc","basc","casc",
"hinca","psizea","z","nij","ni"), na.strings="-999")
summary(clogit)  #summary function
install.packages("conjoint")
library("conjoint")
library(conjoint)
library("conjoint", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
load(tea)
library(conjoint)
install.packages("conjoint")
library(conjoint)
library("conjoint", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
data(tea)
print(tprof)
print(tlevn)
print(tprefm)
print(tsimp)
library(conjoint)
remove.packages("conjoint")
detach("package:graphics", unload=TRUE)
library("graphics", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
install.library(conjoint)
install.packages(conjoint)
install.packages("conjoint")
library("conjoint")
install.packages(c("caret", "Hmisc", "shiny"))
library("AlgDesign", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("clusterSim", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("conjoint", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library(conjoint)
experiment = expand.grid(
+ price = c("low", "medium", "high"),
+ variety = c("black", "green", "red"),
+ kind = c("bags", "granulated", "leafy"),
+ aroma = c("yes", "no"))
design<-caFactorialDesign(data=experiment, type="orthogonal")
library(conjoint)
experiment = expand.grid(
+ price = c("low", "medium", "high"),
+ variety = c("black", "green", "red"),
+ kind = c("bags", "granulated", "leafy"),
+ aroma = c("yes", "no"))
design<-caFactorialDesign(data=experiment, type="orthogonal")
library("conjoint", lib.loc="/Library/Frameworks/R.framework/Versions/3.2/Resources/library")
library("mlogit")
names(Yogurt)
library(mlogit)
data(Yogurt)
names(Yogurt)
summary(Yogurt)
Yogur[1:10,]
Yogurt[1:10,]
Yogurt_choice <- mlogit.data(Yogurt, choice = "choice", shape = "wide", varying = c(2:9),
sep=".")
Yogurt_choice[1:10,]
clogit <- read.csv("~/Desktop/everything R/R_Datasets/clogit.csv",
col.names=c("mode","ttme","invc","invt","gc","chair","hinc",
"psize","indj","indi","aasc","tasc","basc","casc",
"hinca","psizea","z","nij","ni"), na.strings="-999")
clogit[1:12,]
library(readr)
cmc_data <- read_csv("~/Downloads/cmc.data.txt")
View(cmc_data)
cmc<-  cmc_data <- read_csv("~/Downloads/cmc.data.txt",
col.names=c("age","edu","hubedu","nochild","regl","workingstatus","hubocc",
"solindex","media","contracept"))
cmc<-  cmc_data <- read_csv("~/Downloads/cmc.data.txt",
col.names=c("age","edu","hubedu","nochild","regl","workingstatus","hubocc",
"solindex","media","contracept"))
cmc_data <- read_csv("~/Downloads/cmc.data.txt",
col.names=c("age","edu","hubedu","nochild","regl","workingstatus","hubocc",
"solindex","media","contracept"))
cmc_data <- read_csv("~/Downloads/cmc.data.txt",
col.names=c("age","edu","hubedu","nochild","regl","workingstatus","hubocc",
"solindex","media","contracept"))
View(cmc_data)
View(cmc_data)
cmc_data <- col.names=c("age","edu","hubedu","nochild","regl","workingstatus","hubocc",
"solindex","media","contracept")
cmc_data <- read_csv("~/Downloads/cmc.data.txt",
col.names=c("age","edu","hubedu","nochild","regl","workingstatus","hubocc",
"solindex","media","contracept"))
cmc_data <- names=c("age","edu","hubedu","nochild","regl","workingstatus","hubocc",
"solindex","media","contracept")
attach(cmc_data)
cmc_data <- read_table("~/Downloads/cmc.data.txt",
col.names=c("age","edu","hubedu","nochild","regl","workingstatus","hubocc",
"solindex","media","contracept"))
View(cmc_data)
cmc_data <- read_table("~/Downloads/cmc.data.txt", header=F, sep =","
col.names=c("age","edu","hubedu","nochild","regl","workingstatus","hubocc",
"solindex","media","contracept"))
cmc_data <- read.csv("~/Downloads/cmc.data.txt", header=FALSE, sep =","
col.names=c("age","edu","hubedu","nochild","regl","workingstatus","hubocc",
"solindex","media","contracept"))
cmc_data <- read.csv("~/Downloads/cmc.data.txt", header=FALSE, sep =",",
col.names=c("age","edu","hubedu","nochild","regl","workingstatus","hubocc",
"solindex","media","contracept"))
View(cmc_data)
summary(cmc_data)
attach(cmc_data)
edu_high <- edu>3
edu_low <- edu== 1
edu_high <- edu== 4
hubedu_low <-hubedu == 1
hubedu_high <-hubedu == 4
hubocc2 <-  hubocc == 2
hubocc3 <-  hubocc == 3
hubocc3 <-  hubocc == 4
contcept1 <- contracept == 1
contcept2 <- contracept == 2
contcept3 <- contracept == 3
contcept23 <- contracept < 1
(mymodel <-  glm(contcept1 ~ edu_low + edu_high + hubedu_low + hubedu_high + hubocc2 + hubocc3 +
hubocc3 +contcept2 + contcept3, data_data, family="binomial" ))
mymodel <-  glm(contcept1 ~ edu_low + edu_high + hubedu_low + hubedu_high + hubocc2 + hubocc3 +
hubocc3 +contcept2 + contcept3, data_data, family="binomial" )
(mymodel <-  glm(contcept1 ~ edu_low + edu_high + hubedu_low + hubedu_high + hubocc2 + hubocc3 +
hubocc3 +contcept2 + contcept3, data=cmc_data, family="binomial" ))
hubocc2 <-  hubocc == 2
hubocc3 <-  hubocc == 3
hubocc4 <-  hubocc == 4
(mymodel <-  glm(contcept1 ~ edu_low + edu_high + hubedu_low + hubedu_high + hubocc2 + hubocc3 +
hubocc4 +contcept2 + contcept3, data=cmc_data, family="binomial" ))
(mymodel <-  glm(contcept1 ~ edu_low + edu_high + hubedu_low + hubedu_high + hubocc2 + hubocc3 +
hubocc4, data=cmc_data, family="binomial" ))
(cbind(exp(coef(mymodel)), exp(confint(mymodel)))) # print out a output table
(mymodel <-  glm(contcept1 ~ edu_low + edu_high + workingstatus+ nochild + regl + hubedu_low + media+ hubedu_high + hubocc2 + hubocc3 +
hubocc4, data=cmc_data, family="binomial" ))
(mymodel2 <-  glm(contcept1 ~ edu_low + edu_high + workingstatus+ nochild + regl + hubedu_low + media+ hubedu_high + hubocc2 + hubocc3 +
hubocc4, data=cmc_data, family="binomial" ))
(cbind(exp(coef(mymodel2)), exp(confint(mymodel)))) # print out a output table
plot(mymodel)
confmodel <- cbind(exp(coef(mymodel2)), exp(confint(mymodel))) # print out a output table
(mymodel2 <-  glm(contcept1 ~ age+ edu_low + edu_high + workingstatus+ nochild + regl + hubedu_low + media+ hubedu_high + hubocc2 + hubocc3 +
hubocc4, data=cmc_data, family="binomial" ))
(confmodel <- cbind(exp(coef(mymodel2)), exp(confint(mymodel)))) # print out a output table
(mymodel2 <-  glm(contcept1 ~ age+ edu_low + edu_high + workingstatus+ nochild + regl + hubedu_low + media+ hubedu_high + hubocc2 + hubocc3 +
hubocc4, data=cmc_data, family="binomial" ))
(confmodel <- cbind(exp(coef(mymodel2)), exp(confint(mymodel)))) # print out a output table
(confmodel <- cbind(exp(coef(mymodel2)), exp(confint(mymodel2)))) # print out a output table
mypredict  <-  predict(mymodel2, newdata = cmc_data, type= "response" )
cbine(mypredict, edu_lowTRUE )
mypredict  <-  predict(mymodel2, newdata = cmc_data, type= "response" )
cbind(mypredict, edu_lowTRUE )
cbind(mypredict, model2$edu_lowTRUE )
cbind(mypredict, cbc_data$edu_lowTRUE)
cbind(mypredict, cmc_data$edu_lowTRUE)
mypredict  <-  predict(mymodel2, newdata = cmc_data, type= "response" )
cbind(mypredict, cmc_data$edu_lowTRUE)
confusion <-  table(edu_lowTRUE,mypredict<0.5)
confusion <-  table(cmc_data$edu_lowTRUE,mypredict<0.5)
cbind(mypredict, edu_loww)
mypredict  <-  predict(mymodel2, newdata = cmc_data, type= "response" )
cbind(mypredict, edu_loww)
cbind(mypredict, edu_low)
confusion <-  table(edu_low,mypredict<0.5)
prop.table(confusion)
confusion <-  table(edu_low,mypredict<0.5)
rownames(confusion[1] <- "Actual FALSE")
rownames(confusion[2] <- "Actual TRUE")
colname(confusion[3] <- "Predect FALSE")
colname(confusion[4] <- "Predect TRUE")
rownames(confusion[1] <- "Actual FALSE")
rownames(confusion[2] <- "Actual TRUE")
colnames(confusion[3] <- "Predict FALSE")
colnames(confusion[4] <- "Predict TRUE")
prop.table(confusion)
cbind(mypredict, edu_low)
confusion <-  table(edu_low,mypredict<0.5)
rownames(confusion[1,] <- "Actual FALSE")
rownames(confusion[1] <- "Actual FALSE")
rownames(confusion[1,] <- "Actual FALSE")
rownames(confusion[2,] <- "Actual TRUE")
colnames(confusion[,1] <- "Predict FALSE")
colnames(confusion[,2] <- "Predict TRUE")
confusion <-  table(edu_low,mypredict<0.5)
(confusion <-  table(edu_low,mypredict<0.5))
yogurt.data <- data(Yogurt)
library(mlogit)
yogurt.data <- data(Yogurt)
names(yogurt.data)
names(yogurt.data)
View(Yogurt)
View(Yogurt)
yogurt.data <- data(Yogurt)
yogurt.data <- load(Yogurt)
data(Yogurt)
yogurt.data <-  Yogurt
names(Yogurt)
table(yogurt.data)
table(choice)
data(Yogurt)
names(Yogurt)
attach(Yogurt)
table(choice)
View(Yogurt)
Yogurt1:10]
Yogurt[1:10]
Yogurt[1:10]
head(Yogurt[1:10])
Yogurt[1:10,]
Yogurt_choice <- mlogit.data(Yogurt, choice = "choice", shape = "wide", varying = c(2:9), sep=".")
Yogurt[1:10,]
Yogurt_choice[1:10,]
Yogurt_choice[1:20,]
mlogit_mod1 <- mlogit(choice ~ 1 |  price , data = Yogurt, reflevel = alt)
mlogit_mod1 <- mlogit(choice ~ 1 |  price , data = Yogurt_choice, reflevel = alt)
mlogit_mod1 <- mlogit(choice ~ price , data = Yogurt_choice, reflevel = alt)
mlogit_mod1 <- mlogit(choice ~ 1 |  price , data = Yogurt_choice, reflevel = "dannon")
summary(mlogit_mod1)
res2<-mlogit(choice~price+alt,data=Yogurt_choice)
res2
mlogit_mod1 <- mlogit(choice ~ 1 |  feat , data = Yogurt_choice, reflevel = "dannon")
summary(mlogit_mod1)
source('~/WorkingProjects/Yogurt_Mlogit.R')
#go
library(mlogit)
udacious <- c("Chris Saden", "Lauren Castellano",
"Sarah Spikes","Dean Eckles",
"Andy Brown", "Moira Burke",
"Kunal Chawla")
udacious
numbers <- c(1:10)
numbers
numbers <- c(numbers, 11:20)
numbers
udacious <- c("Chris Saden", "Lauren Castellano",
"Sarah Spikes","Dean Eckles",
"Andy Brown", "Moira Burke",
"Kunal Chawla", YOUR_NAME)
udacious <- c("Chris Saden", "Lauren Castellano",
"Sarah Spikes","Dean Eckles",
"Andy Brown", "Moira Burke",
"Kunal Chawla", "carla"")
# Notice how R updates 'udacious' in the workspace.
# It should now say something like 'chr[1:8]'.
# 3. Run the following two lines of code. You can highlight both lines
# of code and run them.
mystery = nchar(udacious)
mystery
mystery = nchar(udacious)
mystery
# Mystery is a vector that contains the number of characters
# for each of the names in udacious, including your name.
# 4. Run this next line of code.
mystery == 11
udacious[mystery == 11]
# It's your Udacious Instructors for the course!
# (and you may be in the output if you're lucky enough
# to have 11 characters in YOUR_NAME) Either way, we
# think you're pretty udacious for taking this course.
mystery == 11
mystery = nchar(udacious)
mystery
mystery == 11
udacious[mystery == 11]
# Scroll down for the answer
data(mtcars)
data(mtcars)
names(mtcars)
# names(mtcars) should output all the variable
# names in the data set. You might notice that the car names
?mtcars
# You can type a '?' before any command or a data set to learn
# more about it. The details and documentation will appear in
# the 'Help' tab.
# 8. To print out the data, run this next line as code.
mtcars
# Scroll up and down in the console to check out the data.
# This is the entire data frame printed out.
# 9. Run these next two functions, one at a time,
# and see if you can figure out what they do.
str(mtcars)
dim(mtcars)
# Scroll down for the answer.
?row.names
# Run this code to see the current row names in the data frame.
row.names(mtcars)
# Run this code to change the row names of the cars to numbers.
row.names(mtcars) <- c(1:32)
# Now print out the data frame by running the code below.
mtcars
Yogurt[1:10,]
library(mlogit)
data(Yogurt)
names(Yogurt)
Yogurt_choice <- mlogit.data(Yogurt, choice = "choice", shape = "long", varying = 2:9)
table(choice)
names(Yogurt)
attach(Yogurt)
table(choice)
Yogurt[1:10,]
Yogurt_choice <- mlogit.data(Yogurt, choice = "choice", shape = "long", varying = c(2:9), sep=".")
Yogurt_choice <- mlogit.data(Yogurt, choice = "choice", shape = "wide", varying = c(2:9), sep=".")
Yogurt_choice[1:20,]
Yogurt_choice <- mlogit.data(Yogurt, choice = "choice", shape = "wide", varying = c(2:9))
Yogurt_choice[1:20,]
Yogurt_choice <- mlogit.data(Yogurt, choice = "choice", shape = "wide", varying = 2:9)
Yogurt_choice[1:20,]
mlogit_mod1 <- mlogit(choice ~ 0 + feat + price, data = Yogurt_choice, reflevel = "dannon")
summary(mlogit_mod1)
mlogit_mod1 <- mlogit(choice ~ 1 |  feat , data = Yogurt_choice, reflevel = "dannon")
summary(mlogit_mod1)
mlogit_mod1 <- mlogit(choice ~ 1 |  feat , data = Yogurt_choice, reflevel = "dannon")
summary(mlogit_mod1)
library(mlogit)
data(Yogurt)
names(Yogurt)
Yogurt_choice <- mlogit.data(Yogurt, choice = "choice", shape = "wide", varying = c(2:9), sep=".")
Yogurt_choice[1:20,]
mlogit_mod1 <- mlogit(choice ~ 1 |  feat , data = Yogurt_choice, reflevel = "dannon")
summary(mlogit_mod1)
setwd("~/deep_water_data_science_files/Sawtooh_CBC_Data")
View(cmc_data)
View(cbc)
View(data)
View(confmodel)
CBC1 <- read_csv("~/deep_water_data_science_files/Sawtooh_CBC_Data/CBC1.csv", header=TRUE, sep=",", stringsAsFactors=TRUE)
CBC1 <- read.csv("~/deep_water_data_science_files/Sawtooh_CBC_Data/CBC1.csv", header=TRUE, sep=",", stringsAsFactors=TRUE)
View(CBC1)
library(mlogit)
CBC_choice <- mlogit.data(CBC1, choice = "Answer", shape = "wide", varying = c(3:8))
CBC_choice <- mlogit.data(CBC1, choice = "Answer", shape = "long", varying = c(3:8))
H <- mlogit.data(CBC1, shape="wide", choice="Answer", varying=c(3:8)
H <- mlogit.data(CBC1, shape="wide", choice="Answer", varying=c(3:8)
)
H <- mlogit.data(CBC1, shape="wide", choice="Answer", varying=c(3:8))
head(CBC1)
TM <- mlogit.data(CBC1, choice = "Answer", shape = "long",alt.levels = c("Brands.nbsp", "Container.Size", "Price", "From.Concentrate","Added.Vitamins.nbsp"))
CBC_choice[1:20,]
View(TM)
View(TM)
TM <- mlogit.data(CBC1, choice = "Answer", shape = "long",
alt.levels = "Task"))
Added.Vitamins.nbsp
View(TM)
